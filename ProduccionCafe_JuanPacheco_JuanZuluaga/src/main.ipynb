{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxPjRHYD8jBh"
      },
      "source": [
        "# Modelo predictivo para la producción cafetera\n",
        "\n",
        "Este proyecto tiene como objetivo implementar una herramienta automatizada para predecir la cosecha de café en un intervalo de fechas dado a partir de imágenes de cafetos mediante técnicas de aprendizaje profundo. La necesidad surge en el contexto de la industria cafetera, donde una predicción precisa de las cosechas futuras es crucial para la planificación de la cosecha, la logística y la negociación de contratos de exportación, que son en su mayoria de venta a futuro.\n",
        "\n",
        "El modelo desarrollado apunta reemplazar métodos tradicionales de muestreo manual, que resultan costosas y tediosas, por un sistema que analiza imágenes y predice cuantos kilos de café se podrán cosechar en un intervalo de fechas dado.\n",
        "\n",
        "\n",
        "## Dependencias\n",
        "\n",
        "Para reproducir nuestro entorno creelo con conda: `conda env create -f environment.yaml`.  \n",
        "También puede instalar las dependencias manualmente `pip install ultralytics labelme2yolo`, asegurese de usar python 3.10."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "  !git clone --depth 1 https://github.com/JuanJoZP/coffee-production-dl.git\n",
        "  !mv coffee-production-dl/ProduccionCafe_JuanPacheco_JuanZuluaga/data .\n",
        "  !mv coffee-production-dl/ProduccionCafe_JuanPacheco_JuanZuluaga/src/environment.yaml .\n",
        "  !rm -rf coffee-production-dl\n"
      ],
      "metadata": {
        "id": "7yCAeL2L9vGs",
        "outputId": "7f2acdd1-58d8-47cf-e603-5ec34b76d260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'coffee-production-dl'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 53 (delta 0), reused 44 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (53/53), 168.36 MiB | 39.92 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!mamba env update -n base -f /contentenvironment.yaml"
      ],
      "metadata": {
        "id": "by5tV9bW9f8V",
        "outputId": "592f0960-1c8c-4493-f731-da4d66ab49a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 219, in iter_dependencies\n",
            "    for req_string in self.metadata.get_all(\"Requires-Dist\", []):\n",
            "                      ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/functools.py\", line 1001, in __get__\n",
            "    val = self.func(instance)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/base.py\", line 394, in metadata\n",
            "    metadata = self._metadata_impl()\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 209, in _metadata_impl\n",
            "    return cast(email.message.Message, self._dist.metadata)\n",
            "                                       ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 617, in metadata\n",
            "    return _adapters.Message(email.message_from_string(text))\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/__init__.py\", line 37, in message_from_string\n",
            "    return Parser(*args, **kws).parsestr(s)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/parser.py\", line 67, in parsestr\n",
            "    return self.parse(StringIO(text), headersonly=headersonly)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/parser.py\", line 56, in parse\n",
            "    feedparser.feed(data)\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 174, in feed\n",
            "    self._call_parse()\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 178, in _call_parse\n",
            "    self._parse()\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 238, in _parsegen\n",
            "    self._parse_headers(headers)\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 512, in _parse_headers\n",
            "    i = line.find(':')\n",
            "        ^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 974, in handle\n",
            "    rv = self.filter(record)\n",
            "         ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 815, in filter\n",
            "    def filter(self, record):\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'condacolab'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4429aa379e49>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q condacolab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcondacolab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcondacolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mamba env update -n base -f /contentenvironment.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'condacolab'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P0oGTm08jBl"
      },
      "outputs": [],
      "source": [
        "!conda env create -f ./environment.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY3COYqZ8jBm"
      },
      "source": [
        "## Arquitectura de la solución\n",
        "\n",
        "La solución propuesta se compone de una serie de modelos encadenados, cada uno encargado de una etapa específica del proceso de predicción. La arquitectura está diseñada en múltiples fases para maximizar la precisión y reducir el ruido en cada etapa:\n",
        "\n",
        "1. Detección de Clústeres de Granos (Modelo detección)\n",
        "\n",
        "   Se utiliza un modelo supervisado de detección de objetos, para localizar los clústeres o agrupaciones de granos de café en las ramas de los cafetos. Este modelo se reentrena con imágenes específicas de cafetos, generando bounding boxes sobre las agrupaciones visibles. Esta primera etapa permite identificar regiones candidatas para análisis más detallado.\n",
        "\n",
        "2. Detección de Granos Individuales (Modelo detección)\n",
        "\n",
        "    Las imágenes recortadas de los clústeres detectados en la etapa anterior se procesan con un segundo modelo de detección de objetos, también supervisado, entrenado para detectar granos individuales. Este enfoque en dos pasos permite reducir el ruido visual del entorno (hojas, ramas, fondo) y estandariza el tamaño de los granos dentro de una imagen más limpia y acotada. Así se mejora la precisión de detección de los granos, incluso en distintos estados de maduración o tamaños.\n",
        "\n",
        "3. (Opcional) Eliminación del ruido (Modelo segmentación)\n",
        "\n",
        "   Cada imagen de grano pasa por un modelo de segmentación no supervisado, cuya función es separar los píxeles pertenecientes al grano de aquellos que representan ruido o fondo. Este paso clasifica cada píxel en dos clases (grano vs. no grano) y puede ser útil para mejorar la precisión del modelo de regresión posterior.\n",
        "\n",
        "4. Estimación del Tiempo de Maduración (Modelo regresión)\n",
        "\n",
        "   Una vez aislado cada grano, se utiliza un modelo de regresión supervisado que estima cuántos días faltan para que ese grano esté listo para cosecha. El modelo puede usar como entrada la imagen segmentada del grano o descriptores derivados de ella, y fue entrenado con ejemplos etiquetados manualmente, basado en conocimiento y experiencia directa con el cultivo del café.\n",
        "\n",
        "5. Cálculo de Producción en un Intervalo de Fechas\n",
        "\n",
        "   Finalmente, el sistema permite al usuario definir un intervalo de fechas de interés. El sistema filtra los granos que estarán listos para cosecha dentro de ese intervalo, estima el número total de granos cosechables, y multiplica este número por un peso promedio por grano para obtener una predicción final en kilos. Además, se podría generar automáticamente un reporte temporal, por ejemplo con la producción proyectada cada dos semanas, facilitando la planificación logística, de mano de obra y de contratos de exportación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzid0Eht8jBo"
      },
      "source": [
        "## Implementación\n",
        "\n",
        "### 1. Detección Clusteres\n",
        "\n",
        "Se etiquetaron manualmente los clusters de granos para las 20 fotos que componen nuestro dataset, se hizo uso del software Labelme.  \n",
        "\n",
        "Una imagen etiquetada se ve así:\n",
        "\n",
        "![image.png](attachment:d72117e1-adf0-4723-a5ed-42c3466d1619.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyXsmEjw8jBq"
      },
      "source": [
        "Se genera el dataset en formato YOLO a partir de las imagenes etiquetadas con labelme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2YvsfvwA1Uk",
        "outputId": "598b43f3-6377-4b43-f254-8455f949fa46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-05-23T20:23:07Z \u001b[0m\u001b[32mINFO \u001b[0m labelme2yolo\u001b[0m\u001b[38;5;8m]\u001b[0m Starting the conversion process...\n",
            "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-05-23T20:23:07Z \u001b[0m\u001b[32mINFO \u001b[0m labelme2yolo\u001b[0m\u001b[38;5;8m]\u001b[0m Read and parsed 20 JSON files.\n",
            "\u001b[32m⠁\u001b[0m [Train] [00:00:00] [\u001b[36m########################################\u001b[34m\u001b[0m\u001b[0m] 14/14 (0s)\n",
            "\u001b[2K\u001b[1B\u001b[1A\u001b[32m \u001b[0m [Train] [00:00:00] [\u001b[36m########################################\u001b[34m\u001b[0m\u001b[0m] 14/14 (0s)\n",
            "\u001b[32m⠁\u001b[0m [Val] [00:00:00] [\u001b[36m########################################\u001b[34m\u001b[0m\u001b[0m] 4/4 (0s)\n",
            "\u001b[2K\u001b[1B\u001b[1A\u001b[32m \u001b[0m [Val] [00:00:00] [\u001b[36m########################################\u001b[34m\u001b[0m\u001b[0m] 4/4 (0s)\n",
            "\u001b[32m⠁\u001b[0m [Test] [00:00:00] [\u001b[36m########################################\u001b[34m\u001b[0m\u001b[0m] 2/2 (0s)\n",
            "\u001b[2K\u001b[1B\u001b[1A\u001b[32m \u001b[0m [Test] [00:00:00] [\u001b[36m########################################\u001b[34m\u001b[0m\u001b[0m] 2/2 (0s)\n",
            "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-05-23T20:23:07Z \u001b[0m\u001b[32mINFO \u001b[0m labelme2yolo\u001b[0m\u001b[38;5;8m]\u001b[0m Creating dataset.yaml file...\n",
            "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-05-23T20:23:07Z \u001b[0m\u001b[32mINFO \u001b[0m labelme2yolo\u001b[0m\u001b[38;5;8m]\u001b[0m Conversion process completed successfully.\n"
          ]
        }
      ],
      "source": [
        "!labelme2yolo --val_size 0.2 --test_size 0.1 --output_format bbox --json_dir ../data/labeled/clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjHAidjd8jBs"
      },
      "source": [
        "Se reentrena el modelo `yolov8l`, primero hacemos grid search para encontrar la mejor combinación de hiperparametros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNCDswa7CeNV"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import itertools\n",
        "import csv\n",
        "\n",
        "params_grid = {\n",
        "    \"batch\": [2, 4],\n",
        "    \"imgsz\": [640, 800],\n",
        "    \"freeze\": [0, 10],\n",
        "    \"lr0\": [0.001, 0.01],\n",
        "    \"optimizer\": [\"SGD\", \"Adam\"]\n",
        "}\n",
        "\n",
        "param_combinations = list(itertools.product(*params_grid.values()))\n",
        "results = []\n",
        "\n",
        "# Grid search\n",
        "for i, combo in enumerate(param_combinations):\n",
        "    params = dict(zip(params_grid.keys(), combo))\n",
        "    name = f\"clusters_tuning_run_{i}\"\n",
        "    print(f\"\\nEntrenando {name} con parámetros: {params}\")\n",
        "\n",
        "    model = YOLO(\"yolov8l.pt\")\n",
        "    model.train(\n",
        "        data=\"../data/labeled/clusters/YOLODataset/dataset.yaml\",\n",
        "        epochs=20,  # pocas epocas para tuning\n",
        "        name=name,\n",
        "        patience=5,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    metrics = model.val()\n",
        "    map50 = metrics.box.ap50\n",
        "    results.append((name, map50, params))\n",
        "\n",
        "# Guardar en CSV\n",
        "with open(\"tuning_results.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"run_name\", \"map50\", \"params\"])\n",
        "    for row in results:\n",
        "        writer.writerow(row)\n",
        "\n",
        "# Elegir el mejor\n",
        "best_run = max(results, key=lambda x: x[1])\n",
        "best_name, best_map, best_params = best_run\n",
        "print(f\"\\nMejor modelo: {best_name} con mAP50 = {best_map}\")\n",
        "\n",
        "best_model_path = f\"runs/detect/{best_name}/weights/best.pt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0zY9V1C8jBv"
      },
      "source": [
        "Se entrena el mejor modelo del grid search por 150 epocas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KfSPKa4a8jBx"
      },
      "outputs": [],
      "source": [
        "model = YOLO(best_model_path)\n",
        "model.train(\n",
        "    data=\"../data/labeled/clusters/YOLODataset/dataset.yaml\",\n",
        "    epochs=150,\n",
        "    name=\"clusters_best_model\",\n",
        "    **best_params\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjylmqcU8jBy"
      },
      "source": [
        "Veamos como se comporta el modelo sobre las imágenes de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b70GAp6MC9Ie",
        "outputId": "adfbb499-214f-4ae0-d3c9-c9154c4adfbb"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'runs/detect/yolov8m/weights/best.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m test_img_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/labeled/clusters/YOLODataset/images/test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m test_label_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/labeled/clusters/YOLODataset/labels/test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns/detect/yolov8m/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_labels\u001b[39m(label_path):\n\u001b[1;32m      8\u001b[0m     labels \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m~/miniconda3/envs/coffee-production-dl/lib/python3.10/site-packages/ultralytics/models/yolo/model.py:53\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTDETR\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m_get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
            "File \u001b[0;32m~/miniconda3/envs/coffee-production-dl/lib/python3.10/site-packages/ultralytics/engine/model.py:151\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
            "File \u001b[0;32m~/miniconda3/envs/coffee-production-dl/lib/python3.10/site-packages/ultralytics/engine/model.py:295\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    292\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights)\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
            "File \u001b[0;32m~/miniconda3/envs/coffee-production-dl/lib/python3.10/site-packages/ultralytics/nn/tasks.py:1334\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;124;03m    Load a single model weights.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;124;03m        (tuple): Tuple containing the model and checkpoint.\u001b[39;00m\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1334\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[1;32m   1336\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/coffee-production-dl/lib/python3.10/site-packages/ultralytics/nn/tasks.py:1239\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1239\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[0;32m~/miniconda3/envs/coffee-production-dl/lib/python3.10/site-packages/ultralytics/utils/patches.py:116\u001b[0m, in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    114\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/coffee-production-dl/lib/python3.10/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
            "File \u001b[0;32m~/miniconda3/envs/coffee-production-dl/lib/python3.10/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "File \u001b[0;32m~/miniconda3/envs/coffee-production-dl/lib/python3.10/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/detect/yolov8m/weights/best.pt'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "test_img_folder = \"../data/labeled/clusters/YOLODataset/images/test\"\n",
        "test_label_folder = \"../data/labeled/clusters/YOLODataset/labels/test\"\n",
        "model = YOLO(best_model_path)\n",
        "\n",
        "def read_labels(label_path):\n",
        "    labels = []\n",
        "    with open(label_path, \"r\") as f:\n",
        "        for line in f.readlines():\n",
        "            labels.append(line.strip().split())\n",
        "    return labels\n",
        "\n",
        "def draw_boxes(image, labels, color):\n",
        "    h, w, _ = image.shape\n",
        "    for label in labels:\n",
        "        class_id, x, y, width, height = map(float, label)\n",
        "        x, y, width, height = int(x * w), int(y * h), int(width * w), int(height * h)\n",
        "        cv2.rectangle(image, (x, y), (x + width, y + height), color, 2)\n",
        "    return image\n",
        "\n",
        "for img_name in os.listdir(test_img_folder):\n",
        "    img_path = os.path.join(test_img_folder, img_name)\n",
        "    label_path = os.path.join(test_label_folder, img_name.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    results = model(img_path)\n",
        "    pred_labels = [[str(obj.cls), *obj.xywh.tolist()] for obj in results[0].boxes]\n",
        "    real_labels = read_labels(label_path)\n",
        "\n",
        "    img_pred = draw_boxes(img.copy(), pred_labels, (0, 255, 0))  # Verde para predicciones\n",
        "    img_real = draw_boxes(img.copy(), real_labels, (255, 0, 0))  # Rojo para etiquetas reales\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    axes[0].imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB))\n",
        "    axes[0].set_title(\"Predicciones del modelo\")\n",
        "    axes[1].imshow(cv2.cvtColor(img_real, cv2.COLOR_BGR2RGB))\n",
        "    axes[1].set_title(\"Etiquetas reales\")\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCq4KSun8jB0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}